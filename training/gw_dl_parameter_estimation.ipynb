{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "\n",
    "# deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "\n",
    "# machine learning\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# signal processing\n",
    "from scipy import signal\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  999\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "torch.use_deterministic_algorithms(True) # Needed for reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wifi-staff-172-24-2-130.net.auckland.ac.nz\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "myHostName = socket.gethostname()\n",
    "print(myHostName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")\n",
    "\n",
    "# number of channels the signal has\n",
    "nc = 1\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 64\n",
    "\n",
    "# number of signals per iteration\n",
    "batch_size = 32\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 200\n",
    "\n",
    "# learning rate\n",
    "lr = 0.001\n",
    "\n",
    "prediction_type = \"classification\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GWDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        # convert to numpy array\n",
    "        self.original_parameters = y\n",
    "        self.parameters = self.original_parameters\n",
    "        # self.augmented_parameters = np.empty(shape = (0, self.parameters.shape[1]))\n",
    "\n",
    "        x = np.transpose(x)\n",
    "        self.original_data = x\n",
    "        self.data = self.original_data\n",
    "        # self.augmented_data = np.empty(shape = (self.data.shape[0], 0))\n",
    "\n",
    "        ### signal augmentation section ###\n",
    "        \n",
    "        temp_data = np.empty(shape = (256, 0)).astype('float32')\n",
    "\n",
    "        for i in range(0, self.data.shape[1]):\n",
    "            signal = self.data[:, i]\n",
    "            signal = signal.reshape(1, -1)\n",
    "\n",
    "            background_noise_segment = signal[:, 0:int(len(signal[0]) - 256)]\n",
    "            signal = signal[:, int(len(signal[0]) - 256):len(signal[0])]\n",
    "\n",
    "            temp_data = np.insert(temp_data, temp_data.shape[1], signal, axis=1)            \n",
    "\n",
    "        self.data = temp_data\n",
    "        ### end signal augmentation section ###\n",
    "\n",
    "    def calc_stats(self):\n",
    "        self.mean = self.data.mean()\n",
    "        print('Dataset mean: ',  self.mean)\n",
    "        self.std = np.std(self.data, axis=None)\n",
    "        print('Dataset std: ',  self.std)\n",
    "\n",
    "        self.parameter_mean = self.parameters.mean()\n",
    "        print('Parameter mean: ',  self.parameter_mean)\n",
    "        self.parameter_std = np.std(self.parameters, axis=None)\n",
    "        print('Parameter std: ',  self.parameter_std)\n",
    "\n",
    "    def get_common(self):\n",
    "        self.common_ylim_signal = (self.data[:,:].min(), self.data[:,:].max())\n",
    "        return self.common_ylim_signal\n",
    "    \n",
    "    def standardize_signal(self, signal):\n",
    "        standardized_signal = (signal - self.mean) / self.std\n",
    "        standardized_signal = standardized_signal / self.scaling_factor\n",
    "        return standardized_signal\n",
    "    \n",
    "    def standardize_parameter(self, parameter):\n",
    "        standardized_parameter = (parameter - self.parameter_mean) / self.parameter_std\n",
    "        return standardized_parameter\n",
    "\n",
    "    ### overloads ###\n",
    "    def __len__(self):\n",
    "        return self.data.shape[1]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        signal = self.data[:, idx]\n",
    "        signal = signal.reshape(1, -1)\n",
    "\n",
    "        parameter = self.parameters[idx,:]\n",
    "        parameter = parameter.reshape(1, -1)\n",
    "\n",
    "        # signal_standardized = self.standardize(signal)\n",
    "        # parameter_standardized = self.standardize_parameter(parameter)\n",
    "\n",
    "        return signal, parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "x = pd.read_csv(\"../data/richers_1764.csv\")\n",
    "y = pd.read_csv(\"../data/richers_1764_parameters.csv\")\n",
    "\n",
    "# remove erroneous signals and select only beta_IC_b as label\n",
    "keep_signals_idx = np.array(y[y['beta1_IC_b'] > 0].index)\n",
    "y = y.iloc[keep_signals_idx,:]\n",
    "y = y['beta1_IC_b']\n",
    "\n",
    "# bin labels to get discretised beta1_IC_b based on Richers et al. 2017\n",
    "ranges = [0, 0.06, 0.17, 1]\n",
    "labels = [0, 1, 2]\n",
    "\n",
    "num_classes = 3\n",
    "\n",
    "y = pd.cut(y, bins=ranges, labels=labels).astype('int')\n",
    "y = y.values\n",
    "\n",
    "print(y)\n",
    "\n",
    "y = np.eye(len(labels))[y]\n",
    "\n",
    "print(y)\n",
    "\n",
    "# select continuous beta_IC_b values for now\n",
    "# y = y[['beta1_IC_b']].astype('float32')\n",
    "# bin labels to get discretised data\n",
    "# y['beta1_IC_b_bins'] = pd.qcut(y['beta1_IC_b'], q=10, labels=False)\n",
    "# y = y[['beta1_IC_b_bins']].astype('float32')\n",
    "# convert to numpy array\n",
    "# y = y.values\n",
    "\n",
    "# drop corresponding signals which have erroneous parameter values\n",
    "x = x.iloc[:,keep_signals_idx]\n",
    "x = x.values.astype('float32')\n",
    "\n",
    "# only transpore x due to compatibility issues with train_test_split\n",
    "x = np.transpose(x)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=manualSeed)\n",
    "\n",
    "train_data = GWDataset(x_train, y_train)\n",
    "test_data = GWDataset(x_test, y_test)\n",
    "\n",
    "# train_data.calc_stats()\n",
    "# test_data.calc_stats()\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/tarineccleston/Documents/software-ds/gw-parameter-estimation/training/gw_dl_parameter_estimation.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tarineccleston/Documents/software-ds/gw-parameter-estimation/training/gw_dl_parameter_estimation.ipynb#X10sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     plt\u001b[39m.\u001b[39mtight_layout()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tarineccleston/Documents/software-ds/gw-parameter-estimation/training/gw_dl_parameter_estimation.ipynb#X10sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/tarineccleston/Documents/software-ds/gw-parameter-estimation/training/gw_dl_parameter_estimation.ipynb#X10sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m plot_waveforms(real_signals_batch, real_parameter_batch)\n",
      "\u001b[1;32m/Users/tarineccleston/Documents/software-ds/gw-parameter-estimation/training/gw_dl_parameter_estimation.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tarineccleston/Documents/software-ds/gw-parameter-estimation/training/gw_dl_parameter_estimation.ipynb#X10sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     fig\u001b[39m.\u001b[39mdelaxes(axes[i])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tarineccleston/Documents/software-ds/gw-parameter-estimation/training/gw_dl_parameter_estimation.ipynb#X10sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m plt\u001b[39m.\u001b[39mtight_layout()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/tarineccleston/Documents/software-ds/gw-parameter-estimation/training/gw_dl_parameter_estimation.ipynb#X10sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m plt\u001b[39m.\u001b[39;49mshow()\n",
      "File \u001b[0;32m~/Documents/software-ds/gw-parameter-estimation/.venv/lib/python3.9/site-packages/matplotlib/pyplot.py:446\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \u001b[39mDisplay all open figures.\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[39mexplicitly there.\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    445\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[0;32m--> 446\u001b[0m \u001b[39mreturn\u001b[39;00m _get_backend_mod()\u001b[39m.\u001b[39;49mshow(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/software-ds/gw-parameter-estimation/.venv/lib/python3.9/site-packages/matplotlib_inline/backend_inline.py:90\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m     \u001b[39mfor\u001b[39;00m figure_manager \u001b[39min\u001b[39;00m Gcf\u001b[39m.\u001b[39mget_all_fig_managers():\n\u001b[0;32m---> 90\u001b[0m         display(\n\u001b[1;32m     91\u001b[0m             figure_manager\u001b[39m.\u001b[39;49mcanvas\u001b[39m.\u001b[39;49mfigure,\n\u001b[1;32m     92\u001b[0m             metadata\u001b[39m=\u001b[39;49m_fetch_figure_metadata(figure_manager\u001b[39m.\u001b[39;49mcanvas\u001b[39m.\u001b[39;49mfigure)\n\u001b[1;32m     93\u001b[0m         )\n\u001b[1;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     show\u001b[39m.\u001b[39m_to_draw \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/Documents/software-ds/gw-parameter-estimation/.venv/lib/python3.9/site-packages/IPython/core/display_functions.py:298\u001b[0m, in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m     publish_display_data(data\u001b[39m=\u001b[39mobj, metadata\u001b[39m=\u001b[39mmetadata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 298\u001b[0m     format_dict, md_dict \u001b[39m=\u001b[39m \u001b[39mformat\u001b[39;49m(obj, include\u001b[39m=\u001b[39;49minclude, exclude\u001b[39m=\u001b[39;49mexclude)\n\u001b[1;32m    299\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m format_dict:\n\u001b[1;32m    300\u001b[0m         \u001b[39m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/software-ds/gw-parameter-estimation/.venv/lib/python3.9/site-packages/IPython/core/formatters.py:179\u001b[0m, in \u001b[0;36mDisplayFormatter.format\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    177\u001b[0m md \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m     data \u001b[39m=\u001b[39m formatter(obj)\n\u001b[1;32m    180\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    181\u001b[0m     \u001b[39m# FIXME: log the exception\u001b[39;00m\n\u001b[1;32m    182\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/software-ds/gw-parameter-estimation/.venv/lib/python3.9/site-packages/decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m kwsyntax:\n\u001b[1;32m    231\u001b[0m     args, kw \u001b[39m=\u001b[39m fix(args, kw, sig)\n\u001b[0;32m--> 232\u001b[0m \u001b[39mreturn\u001b[39;00m caller(func, \u001b[39m*\u001b[39;49m(extras \u001b[39m+\u001b[39;49m args), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/Documents/software-ds/gw-parameter-estimation/.venv/lib/python3.9/site-packages/IPython/core/formatters.py:223\u001b[0m, in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 223\u001b[0m     r \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    224\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     \u001b[39m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[1;32m    226\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_return(\u001b[39mNone\u001b[39;00m, args[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/Documents/software-ds/gw-parameter-estimation/.venv/lib/python3.9/site-packages/IPython/core/formatters.py:340\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 340\u001b[0m     \u001b[39mreturn\u001b[39;00m printer(obj)\n\u001b[1;32m    341\u001b[0m \u001b[39m# Finally look for special method names\u001b[39;00m\n\u001b[1;32m    342\u001b[0m method \u001b[39m=\u001b[39m get_real_method(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_method)\n",
      "File \u001b[0;32m~/Documents/software-ds/gw-parameter-estimation/.venv/lib/python3.9/site-packages/IPython/core/pylabtools.py:152\u001b[0m, in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend_bases\u001b[39;00m \u001b[39mimport\u001b[39;00m FigureCanvasBase\n\u001b[1;32m    150\u001b[0m     FigureCanvasBase(fig)\n\u001b[0;32m--> 152\u001b[0m fig\u001b[39m.\u001b[39;49mcanvas\u001b[39m.\u001b[39;49mprint_figure(bytes_io, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m    153\u001b[0m data \u001b[39m=\u001b[39m bytes_io\u001b[39m.\u001b[39mgetvalue()\n\u001b[1;32m    154\u001b[0m \u001b[39mif\u001b[39;00m fmt \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msvg\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/software-ds/gw-parameter-estimation/.venv/lib/python3.9/site-packages/matplotlib/backend_bases.py:2346\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2344\u001b[0m \u001b[39mif\u001b[39;00m bbox_inches:\n\u001b[1;32m   2345\u001b[0m     \u001b[39mif\u001b[39;00m bbox_inches \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtight\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 2346\u001b[0m         bbox_inches \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49mget_tightbbox(\n\u001b[1;32m   2347\u001b[0m             renderer, bbox_extra_artists\u001b[39m=\u001b[39;49mbbox_extra_artists)\n\u001b[1;32m   2348\u001b[0m         \u001b[39mif\u001b[39;00m pad_inches \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2349\u001b[0m             pad_inches \u001b[39m=\u001b[39m rcParams[\u001b[39m'\u001b[39m\u001b[39msavefig.pad_inches\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/software-ds/gw-parameter-estimation/.venv/lib/python3.9/site-packages/matplotlib/figure.py:1776\u001b[0m, in \u001b[0;36mFigureBase.get_tightbbox\u001b[0;34m(self, renderer, bbox_extra_artists)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     artists \u001b[39m=\u001b[39m bbox_extra_artists\n\u001b[1;32m   1775\u001b[0m \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[0;32m-> 1776\u001b[0m     bbox \u001b[39m=\u001b[39m a\u001b[39m.\u001b[39;49mget_tightbbox(renderer)\n\u001b[1;32m   1777\u001b[0m     \u001b[39mif\u001b[39;00m bbox \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1778\u001b[0m         bb\u001b[39m.\u001b[39mappend(bbox)\n",
      "File \u001b[0;32m~/Documents/software-ds/gw-parameter-estimation/.venv/lib/python3.9/site-packages/matplotlib/axes/_base.py:4408\u001b[0m, in \u001b[0;36m_AxesBase.get_tightbbox\u001b[0;34m(self, renderer, call_axes_locator, bbox_extra_artists, for_layout_only)\u001b[0m\n\u001b[1;32m   4405\u001b[0m     bbox_artists \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_default_bbox_extra_artists()\n\u001b[1;32m   4407\u001b[0m \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m bbox_artists:\n\u001b[0;32m-> 4408\u001b[0m     bbox \u001b[39m=\u001b[39m a\u001b[39m.\u001b[39;49mget_tightbbox(renderer)\n\u001b[1;32m   4409\u001b[0m     \u001b[39mif\u001b[39;00m (bbox \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   4410\u001b[0m             \u001b[39mand\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39m<\u001b[39m bbox\u001b[39m.\u001b[39mwidth \u001b[39m<\u001b[39m np\u001b[39m.\u001b[39minf\n\u001b[1;32m   4411\u001b[0m             \u001b[39mand\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39m<\u001b[39m bbox\u001b[39m.\u001b[39mheight \u001b[39m<\u001b[39m np\u001b[39m.\u001b[39minf):\n\u001b[1;32m   4412\u001b[0m         bb\u001b[39m.\u001b[39mappend(bbox)\n",
      "File \u001b[0;32m~/Documents/software-ds/gw-parameter-estimation/.venv/lib/python3.9/site-packages/matplotlib/artist.py:367\u001b[0m, in \u001b[0;36mArtist.get_tightbbox\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_tightbbox\u001b[39m(\u001b[39mself\u001b[39m, renderer\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    353\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \u001b[39m    Like `.Artist.get_window_extent`, but includes any clipping.\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[39m        The enclosing bounding box (in figure pixel coordinates).\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     bbox \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_window_extent(renderer)\n\u001b[1;32m    368\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_clip_on():\n\u001b[1;32m    369\u001b[0m         clip_box \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_clip_box()\n",
      "File \u001b[0;32m~/Documents/software-ds/gw-parameter-estimation/.venv/lib/python3.9/site-packages/matplotlib/spines.py:158\u001b[0m, in \u001b[0;36mSpine.get_window_extent\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[39mreturn\u001b[39;00m bb\n\u001b[1;32m    157\u001b[0m bboxes \u001b[39m=\u001b[39m [bb]\n\u001b[0;32m--> 158\u001b[0m drawn_ticks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maxis\u001b[39m.\u001b[39;49m_update_ticks()\n\u001b[1;32m    160\u001b[0m major_tick \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m({\u001b[39m*\u001b[39mdrawn_ticks} \u001b[39m&\u001b[39m {\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis\u001b[39m.\u001b[39mmajorTicks}), \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    161\u001b[0m minor_tick \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m({\u001b[39m*\u001b[39mdrawn_ticks} \u001b[39m&\u001b[39m {\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis\u001b[39m.\u001b[39mminorTicks}), \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/software-ds/gw-parameter-estimation/.venv/lib/python3.9/site-packages/matplotlib/axis.py:1262\u001b[0m, in \u001b[0;36mAxis._update_ticks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1257\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_ticks\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1258\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[39m    Update ticks (position and labels) using the current data interval of\u001b[39;00m\n\u001b[1;32m   1260\u001b[0m \u001b[39m    the axes.  Return the list of ticks that will be drawn.\u001b[39;00m\n\u001b[1;32m   1261\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1262\u001b[0m     major_locs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_majorticklocs()\n\u001b[1;32m   1263\u001b[0m     major_labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmajor\u001b[39m.\u001b[39mformatter\u001b[39m.\u001b[39mformat_ticks(major_locs)\n\u001b[1;32m   1264\u001b[0m     major_ticks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_major_ticks(\u001b[39mlen\u001b[39m(major_locs))\n",
      "File \u001b[0;32m~/Documents/software-ds/gw-parameter-estimation/.venv/lib/python3.9/site-packages/matplotlib/axis.py:1484\u001b[0m, in \u001b[0;36mAxis.get_majorticklocs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1482\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_majorticklocs\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1483\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return this Axis' major tick locations in data coordinates.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1484\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmajor\u001b[39m.\u001b[39;49mlocator()\n",
      "File \u001b[0;32m~/Documents/software-ds/gw-parameter-estimation/.venv/lib/python3.9/site-packages/matplotlib/ticker.py:2136\u001b[0m, in \u001b[0;36mMaxNLocator.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   2135\u001b[0m     vmin, vmax \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis\u001b[39m.\u001b[39mget_view_interval()\n\u001b[0;32m-> 2136\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtick_values(vmin, vmax)\n",
      "File \u001b[0;32m~/Documents/software-ds/gw-parameter-estimation/.venv/lib/python3.9/site-packages/matplotlib/ticker.py:2144\u001b[0m, in \u001b[0;36mMaxNLocator.tick_values\u001b[0;34m(self, vmin, vmax)\u001b[0m\n\u001b[1;32m   2141\u001b[0m     vmin \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mvmax\n\u001b[1;32m   2142\u001b[0m vmin, vmax \u001b[39m=\u001b[39m mtransforms\u001b[39m.\u001b[39mnonsingular(\n\u001b[1;32m   2143\u001b[0m     vmin, vmax, expander\u001b[39m=\u001b[39m\u001b[39m1e-13\u001b[39m, tiny\u001b[39m=\u001b[39m\u001b[39m1e-14\u001b[39m)\n\u001b[0;32m-> 2144\u001b[0m locs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raw_ticks(vmin, vmax)\n\u001b[1;32m   2146\u001b[0m prune \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prune\n\u001b[1;32m   2147\u001b[0m \u001b[39mif\u001b[39;00m prune \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mlower\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/software-ds/gw-parameter-estimation/.venv/lib/python3.9/site-packages/matplotlib/ticker.py:2129\u001b[0m, in \u001b[0;36mMaxNLocator._raw_ticks\u001b[0;34m(self, vmin, vmax)\u001b[0m\n\u001b[1;32m   2127\u001b[0m ticks \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(low, high \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m step \u001b[39m+\u001b[39m best_vmin\n\u001b[1;32m   2128\u001b[0m \u001b[39m# Count only the ticks that will be displayed.\u001b[39;00m\n\u001b[0;32m-> 2129\u001b[0m nticks \u001b[39m=\u001b[39m ((ticks \u001b[39m<\u001b[39;49m\u001b[39m=\u001b[39;49m _vmax) \u001b[39m&\u001b[39m (ticks \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m _vmin))\u001b[39m.\u001b[39msum()\n\u001b[1;32m   2130\u001b[0m \u001b[39mif\u001b[39;00m nticks \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_min_n_ticks:\n\u001b[1;32m   2131\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "real_signals_batch, real_parameter_batch  = next(iter(train_loader))\n",
    "\n",
    "common_ylim = (real_signals_batch[:,:,:].min(), real_signals_batch[:,:,:].max())\n",
    "parameter_names = ['beta1_IC_b']\n",
    "\n",
    "def plot_waveforms(real_signals_batch, real_parameter_batch):\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(15, 12))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Plot each signal on a separate subplot\n",
    "    for i, ax in enumerate(axes):\n",
    "        x = np.arange(real_signals_batch.size(dim=2))\n",
    "        y = real_signals_batch[i, :, :].flatten()\n",
    "        ax.plot(x, y)\n",
    "\n",
    "        ax.axvline(x=50, color='black', linestyle='--', alpha=0.5)\n",
    "        ax.set_title(f'Signal {i + 1}')\n",
    "        ax.grid(True)\n",
    "        ax.set_ylim(common_ylim)\n",
    "\n",
    "        # Get parameter values as a NumPy array\n",
    "        parameters = real_parameter_batch[i, :].numpy()[0]\n",
    "\n",
    "        # Combine parameter names and values, format as a string\n",
    "        parameters_with_names = f'{parameter_names[0]}: {parameters[0]:.6f}'\n",
    "        ax.set_xlabel(f'Parameters:\\n{parameters_with_names}')\n",
    "\n",
    "    for i in range(512, 8 * 4):\n",
    "        fig.delaxes(axes[i])\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "plot_waveforms(real_signals_batch, real_parameter_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization called on classifier\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Discriminator, self).__init__()\n",
    "            self.main = nn.Sequential(\n",
    "                nn.Conv1d(nc, ndf, kernel_size=16, stride=2, padding=1, bias=False),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.Dropout1d(0.2),\n",
    "\n",
    "                nn.Conv1d(ndf, ndf * 2, kernel_size=8, stride=2, padding=1, bias=False),\n",
    "                nn.BatchNorm1d(ndf * 2),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.Dropout1d(0.2),\n",
    "\n",
    "                nn.Conv1d(ndf * 2, ndf * 4, kernel_size=4,\n",
    "                        stride=2, padding=1, bias=False),\n",
    "                nn.BatchNorm1d(ndf * 4),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.Dropout1d(0.2),\n",
    "\n",
    "                nn.Conv1d(ndf * 4, ndf * 8, kernel_size=4,\n",
    "                        stride=2, padding=1, bias=False),\n",
    "                # nn.BatchNorm1d(ndf * 8),\n",
    "                # nn.LeakyReLU(0.2, inplace=True),\n",
    "                # nn.Dropout1d(0.2),\n",
    "\n",
    "                # nn.Conv1d(ndf * 8, ndf * 16, kernel_size=4,\n",
    "                #         stride=2, padding=0, bias=False),\n",
    "                # nn.BatchNorm1d(ndf * 16),\n",
    "                # nn.LeakyReLU(0.2, inplace=True),\n",
    "                # nn.Dropout1d(0.2),\n",
    "\n",
    "                # nn.Conv1d(ndf * 16, ndf * 32, kernel_size=4,\n",
    "                #         stride=2, padding=1, bias=False),\n",
    "                # nn.BatchNorm1d(ndf * 32),\n",
    "                # nn.LeakyReLU(0.2, inplace=True),\n",
    "                # nn.Dropout1d(0.2),\n",
    "\n",
    "                # nn.Conv1d(ndf * 32, ndf * 64, kernel_size=4,\n",
    "                #         stride=2, padding=1, bias=False),\n",
    "                # nn.BatchNorm1d(ndf * 64),\n",
    "                # nn.LeakyReLU(0.2, inplace=True),\n",
    "                # nn.Dropout1d(0.2),\n",
    "                \n",
    "                # nn.Conv1d(ndf * 64, nc, kernel_size=4,\n",
    "                #         stride=2, padding=0, bias=False)\n",
    "            )\n",
    "\n",
    "            self.fc_reg = nn.Sequential(\n",
    "                nn.LazyLinear(1),\n",
    "            )\n",
    "\n",
    "            self.fc_class = nn.Sequential(\n",
    "                nn.LazyLinear(3),\n",
    "                nn.Softmax(dim=1),\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.main(x)\n",
    "            x = x.view(x.shape[0], -1)  # Flatten the tensor\n",
    "            if (prediction_type == \"regression\"):\n",
    "                x = self.fc_reg(x)\n",
    "            else:\n",
    "                x = self.fc_class(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv1d(1, 64, kernel_size=(16,), stride=(2,), padding=(1,), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Dropout1d(p=0.2, inplace=False)\n",
      "    (3): Conv1d(64, 128, kernel_size=(8,), stride=(2,), padding=(1,), bias=False)\n",
      "    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (6): Dropout1d(p=0.2, inplace=False)\n",
      "    (7): Conv1d(128, 256, kernel_size=(4,), stride=(2,), padding=(1,), bias=False)\n",
      "    (8): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (10): Dropout1d(p=0.2, inplace=False)\n",
      "    (11): Conv1d(256, 512, kernel_size=(4,), stride=(2,), padding=(1,), bias=False)\n",
      "  )\n",
      "  (fc_reg): Sequential(\n",
      "    (0): LazyLinear(in_features=0, out_features=1, bias=True)\n",
      "  )\n",
      "  (fc_class): Sequential(\n",
      "    (0): LazyLinear(in_features=0, out_features=3, bias=True)\n",
      "    (1): Softmax(dim=1)\n",
      "  )\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1              [-1, 64, 122]           1,024\n",
      "         LeakyReLU-2              [-1, 64, 122]               0\n",
      "         Dropout1d-3              [-1, 64, 122]               0\n",
      "            Conv1d-4              [-1, 128, 59]          65,536\n",
      "       BatchNorm1d-5              [-1, 128, 59]             256\n",
      "         LeakyReLU-6              [-1, 128, 59]               0\n",
      "         Dropout1d-7              [-1, 128, 59]               0\n",
      "            Conv1d-8              [-1, 256, 29]         131,072\n",
      "       BatchNorm1d-9              [-1, 256, 29]             512\n",
      "        LeakyReLU-10              [-1, 256, 29]               0\n",
      "        Dropout1d-11              [-1, 256, 29]               0\n",
      "           Conv1d-12              [-1, 512, 14]         524,288\n",
      "           Linear-13                    [-1, 3]          21,507\n",
      "          Softmax-14                    [-1, 3]               0\n",
      "================================================================\n",
      "Total params: 744,195\n",
      "Trainable params: 744,195\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.69\n",
      "Params size (MB): 2.84\n",
      "Estimated Total Size (MB): 3.53\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarineccleston/Documents/software-ds/gw-parameter-estimation/.venv/lib/python3.9/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "net = Discriminator().to(device)\n",
    "net.apply(weights_init)\n",
    "\n",
    "print(net)\n",
    "\n",
    "model = Discriminator()\n",
    "summary(model, input_size=(1, 256))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss functions and Optimisers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (prediction_type == \"regression\"):\n",
    "    criterion = nn.MSELoss()\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 loss: 49.875\n",
      "Epoch: 2 loss: 49.338\n",
      "Epoch: 3 loss: 48.501\n",
      "Epoch: 4 loss: 48.724\n",
      "Epoch: 5 loss: 48.211\n",
      "Epoch: 6 loss: 47.922\n",
      "Epoch: 7 loss: 47.931\n",
      "Epoch: 8 loss: 48.072\n",
      "Epoch: 9 loss: 47.914\n",
      "Epoch: 10 loss: 47.671\n",
      "Epoch: 11 loss: 47.748\n",
      "Epoch: 12 loss: 47.382\n",
      "Epoch: 13 loss: 47.555\n",
      "Epoch: 14 loss: 47.392\n",
      "Epoch: 15 loss: 47.170\n",
      "Epoch: 16 loss: 47.233\n",
      "Epoch: 17 loss: 47.434\n",
      "Epoch: 18 loss: 47.036\n",
      "Epoch: 19 loss: 47.223\n",
      "Epoch: 20 loss: 47.281\n",
      "Epoch: 21 loss: 46.896\n",
      "Epoch: 22 loss: 46.614\n",
      "Epoch: 23 loss: 46.568\n",
      "Epoch: 24 loss: 46.383\n",
      "Epoch: 25 loss: 46.152\n",
      "Epoch: 26 loss: 46.534\n",
      "Epoch: 27 loss: 46.069\n",
      "Epoch: 28 loss: 46.437\n",
      "Epoch: 29 loss: 45.689\n",
      "Epoch: 30 loss: 45.769\n",
      "Epoch: 31 loss: 45.795\n",
      "Epoch: 32 loss: 45.911\n",
      "Epoch: 33 loss: 45.778\n",
      "Epoch: 34 loss: 45.395\n",
      "Epoch: 35 loss: 45.287\n",
      "Epoch: 36 loss: 45.420\n",
      "Epoch: 37 loss: 45.317\n",
      "Epoch: 38 loss: 45.089\n",
      "Epoch: 39 loss: 45.328\n",
      "Epoch: 40 loss: 45.071\n",
      "Epoch: 41 loss: 44.903\n",
      "Epoch: 42 loss: 45.070\n",
      "Epoch: 43 loss: 45.082\n",
      "Epoch: 44 loss: 44.597\n",
      "Epoch: 45 loss: 44.848\n",
      "Epoch: 46 loss: 44.550\n",
      "Epoch: 47 loss: 44.463\n",
      "Epoch: 48 loss: 44.590\n",
      "Epoch: 49 loss: 44.460\n",
      "Epoch: 50 loss: 44.139\n",
      "Epoch: 51 loss: 43.867\n",
      "Epoch: 52 loss: 44.092\n",
      "Epoch: 53 loss: 44.139\n",
      "Epoch: 54 loss: 43.960\n",
      "Epoch: 55 loss: 43.901\n",
      "Epoch: 56 loss: 43.575\n",
      "Epoch: 57 loss: 43.739\n",
      "Epoch: 58 loss: 43.515\n",
      "Epoch: 59 loss: 43.642\n",
      "Epoch: 60 loss: 43.493\n",
      "Epoch: 61 loss: 42.931\n",
      "Epoch: 62 loss: 43.443\n",
      "Epoch: 63 loss: 43.429\n",
      "Epoch: 64 loss: 43.393\n",
      "Epoch: 65 loss: 42.937\n",
      "Epoch: 66 loss: 42.728\n",
      "Epoch: 67 loss: 43.140\n",
      "Epoch: 68 loss: 42.357\n",
      "Epoch: 69 loss: 42.861\n",
      "Epoch: 70 loss: 42.511\n",
      "Epoch: 71 loss: 42.677\n",
      "Epoch: 72 loss: 42.688\n",
      "Epoch: 73 loss: 42.670\n",
      "Epoch: 74 loss: 42.442\n",
      "Epoch: 75 loss: 42.660\n",
      "Epoch: 76 loss: 42.302\n",
      "Epoch: 77 loss: 42.479\n",
      "Epoch: 78 loss: 41.958\n",
      "Epoch: 79 loss: 42.277\n",
      "Epoch: 80 loss: 41.634\n",
      "Epoch: 81 loss: 42.203\n",
      "Epoch: 82 loss: 41.667\n",
      "Epoch: 83 loss: 41.938\n",
      "Epoch: 84 loss: 42.130\n",
      "Epoch: 85 loss: 41.996\n",
      "Epoch: 86 loss: 41.759\n",
      "Epoch: 87 loss: 41.441\n",
      "Epoch: 88 loss: 41.856\n",
      "Epoch: 89 loss: 42.251\n",
      "Epoch: 90 loss: 41.627\n",
      "Epoch: 91 loss: 41.806\n",
      "Epoch: 92 loss: 41.620\n",
      "Epoch: 93 loss: 41.476\n",
      "Epoch: 94 loss: 41.644\n",
      "Epoch: 95 loss: 41.155\n",
      "Epoch: 96 loss: 41.045\n",
      "Epoch: 97 loss: 41.126\n",
      "Epoch: 98 loss: 40.688\n",
      "Epoch: 99 loss: 41.222\n",
      "Epoch: 100 loss: 41.023\n",
      "Epoch: 101 loss: 41.037\n",
      "Epoch: 102 loss: 40.711\n",
      "Epoch: 103 loss: 40.993\n",
      "Epoch: 104 loss: 40.962\n",
      "Epoch: 105 loss: 40.844\n",
      "Epoch: 106 loss: 40.850\n",
      "Epoch: 107 loss: 40.676\n",
      "Epoch: 108 loss: 40.956\n",
      "Epoch: 109 loss: 40.705\n",
      "Epoch: 110 loss: 40.542\n",
      "Epoch: 111 loss: 40.350\n",
      "Epoch: 112 loss: 40.771\n",
      "Epoch: 113 loss: 40.239\n",
      "Epoch: 114 loss: 40.446\n",
      "Epoch: 115 loss: 40.369\n",
      "Epoch: 116 loss: 40.227\n",
      "Epoch: 117 loss: 40.134\n",
      "Epoch: 118 loss: 40.802\n",
      "Epoch: 119 loss: 40.605\n",
      "Epoch: 120 loss: 40.389\n",
      "Epoch: 121 loss: 39.912\n",
      "Epoch: 122 loss: 39.603\n",
      "Epoch: 123 loss: 39.889\n",
      "Epoch: 124 loss: 39.520\n",
      "Epoch: 125 loss: 39.863\n",
      "Epoch: 126 loss: 39.841\n",
      "Epoch: 127 loss: 39.859\n",
      "Epoch: 128 loss: 40.053\n",
      "Epoch: 129 loss: 39.766\n",
      "Epoch: 130 loss: 39.956\n",
      "Epoch: 131 loss: 39.752\n",
      "Epoch: 132 loss: 40.077\n",
      "Epoch: 133 loss: 39.751\n",
      "Epoch: 134 loss: 39.956\n",
      "Epoch: 135 loss: 39.712\n",
      "Epoch: 136 loss: 39.725\n",
      "Epoch: 137 loss: 39.785\n",
      "Epoch: 138 loss: 39.425\n",
      "Epoch: 139 loss: 39.582\n",
      "Epoch: 140 loss: 39.336\n",
      "Epoch: 141 loss: 39.039\n",
      "Epoch: 142 loss: 39.387\n",
      "Epoch: 143 loss: 39.289\n",
      "Epoch: 144 loss: 39.519\n",
      "Epoch: 145 loss: 39.088\n",
      "Epoch: 146 loss: 39.454\n",
      "Epoch: 147 loss: 39.187\n",
      "Epoch: 148 loss: 39.607\n",
      "Epoch: 149 loss: 39.518\n",
      "Epoch: 150 loss: 39.176\n",
      "Epoch: 151 loss: 39.797\n",
      "Epoch: 152 loss: 39.417\n",
      "Epoch: 153 loss: 39.264\n",
      "Epoch: 154 loss: 39.047\n",
      "Epoch: 155 loss: 39.201\n",
      "Epoch: 156 loss: 38.626\n",
      "Epoch: 157 loss: 39.150\n",
      "Epoch: 158 loss: 38.877\n",
      "Epoch: 159 loss: 38.970\n",
      "Epoch: 160 loss: 38.566\n",
      "Epoch: 161 loss: 39.119\n",
      "Epoch: 162 loss: 38.805\n",
      "Epoch: 163 loss: 38.623\n",
      "Epoch: 164 loss: 38.920\n",
      "Epoch: 165 loss: 39.108\n",
      "Epoch: 166 loss: 39.022\n",
      "Epoch: 167 loss: 38.942\n",
      "Epoch: 168 loss: 38.911\n",
      "Epoch: 169 loss: 38.677\n",
      "Epoch: 170 loss: 39.115\n",
      "Epoch: 171 loss: 38.735\n",
      "Epoch: 172 loss: 38.644\n",
      "Epoch: 173 loss: 38.203\n",
      "Epoch: 174 loss: 38.573\n",
      "Epoch: 175 loss: 38.641\n",
      "Epoch: 176 loss: 38.798\n",
      "Epoch: 177 loss: 38.404\n",
      "Epoch: 178 loss: 38.704\n",
      "Epoch: 179 loss: 38.686\n",
      "Epoch: 180 loss: 38.254\n",
      "Epoch: 181 loss: 38.278\n",
      "Epoch: 182 loss: 38.470\n",
      "Epoch: 183 loss: 38.623\n",
      "Epoch: 184 loss: 38.545\n",
      "Epoch: 185 loss: 38.098\n",
      "Epoch: 186 loss: 38.261\n",
      "Epoch: 187 loss: 38.068\n",
      "Epoch: 188 loss: 38.251\n",
      "Epoch: 189 loss: 38.407\n",
      "Epoch: 190 loss: 38.338\n",
      "Epoch: 191 loss: 38.102\n",
      "Epoch: 192 loss: 37.950\n",
      "Epoch: 193 loss: 37.733\n",
      "Epoch: 194 loss: 37.927\n",
      "Epoch: 195 loss: 38.094\n",
      "Epoch: 196 loss: 38.305\n",
      "Epoch: 197 loss: 38.003\n",
      "Epoch: 198 loss: 38.046\n",
      "Epoch: 199 loss: 38.240\n",
      "Epoch: 200 loss: 37.757\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "C_gradients = []\n",
    "C_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device, dtype=torch.float32)\n",
    "        labels = labels.to(device, dtype=torch.float32)\n",
    "        labels = labels.squeeze(1)\n",
    "\n",
    "        # print(inputs)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # save losses and gradients for plotting later\n",
    "        # C_gradients.append([param.grad.norm().item() for param in net.parameters()])\n",
    "        C_losses.append(loss.item())\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(\"Epoch: \"f'{epoch + 1} loss: {running_loss:.3f}')\n",
    "    running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe visualise this later. Not sure what's going on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get the total number of layers in the classifier\n",
    "# C_gradients = np.array(C_gradients)\n",
    "# num_layers = C_gradients.shape[1]\n",
    "\n",
    "# # Plot the gradients over training epochs\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# for i in range(num_layers):\n",
    "#     # Calculate alpha value based on layer index\n",
    "#     alpha = 1 - (i / num_layers)  # Higher layers are more transparent\n",
    "#     plt.plot(C_gradients[:, i], label=f'Layer {i}', alpha=alpha, color=(1, 0, 0, alpha))\n",
    "\n",
    "# plt.xlabel('iterations')\n",
    "# plt.ylabel('Gradient Magnitude')\n",
    "# plt.title('Classifier Gradients')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Classifier Loss During Training\")\n",
    "plt.plot(C_losses,label=\"C\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mtx = torch.zeros(num_classes, num_classes)\n",
    "\n",
    "cum_true_indices = torch.Tensor().to(device, dtype=torch.float32)\n",
    "cum_predicted_indices = torch.Tensor().to(device, dtype=torch.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device, dtype=torch.float32)\n",
    "        labels = labels.to(device, dtype=torch.long)  # Use torch.long for class indices\n",
    "        labels = labels.squeeze(1)\n",
    "\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        true_indices = torch.argmax(labels, dim=1)\n",
    "        predicted_indices = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        cum_true_indices = torch.concat([cum_true_indices, true_indices], axis=0)\n",
    "        cum_predicted_indices = torch.concat([cum_predicted_indices, predicted_indices], axis=0)\n",
    "\n",
    "        # Update the confusion matrix\n",
    "        # batch_confusion_mtx = confusion_matrix(true_indices.cpu(), predicted_indices.cpu(), labels=range(num_classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "tensor([[61., 15.,  0.],\n",
      "        [35., 38.,  0.],\n",
      "        [13.,  7.,  0.]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mtx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gw-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
